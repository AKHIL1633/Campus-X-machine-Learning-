{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing packages if needed","metadata":{}},{"cell_type":"code","source":"!pip install keras","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing packages","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random as rn\n\nimport tensorflow as tf\nimport keras\n\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.models import Model, load_model,Sequential\nfrom tensorflow.keras.layers import Input, Dense,Conv2D,MaxPool2D,Activation,Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\nfrom tensorflow.keras import regularizers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up paths","metadata":{}},{"cell_type":"code","source":"dir_path = '/kaggle/input/rvlcdip/'\nos.listdir(dir_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/rvlcdip/labels_final.csv')\nprint(traindf.head())\nprint(traindf.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading and Visualising the Images","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load and display a .tif image\nimage_path = '/kaggle/input/rvlcdip/data_final/imagesv/v/o/h/voh71d00/509132755+-2755.tif'\nimage = Image.open(image_path)\n\nplt.imshow(image)\nplt.axis('off')  # Turn off axis labels\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chekcing how many class images are present","metadata":{}},{"cell_type":"code","source":"traindf[\"label\"].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing ImageDataGenerator with Augmentation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.2\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up train Generator","metadata":{}},{"cell_type":"code","source":"%%time\n\n# datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe= traindf,\n                                              directory='/kaggle/input/rvlcdip/data_final/',\n                                              x_col = 'path',\n                                              y_col = 'label',\n                                              subset = 'training',\n                                              batch_size=100,\n                                              seed=42,\n                                              shuffle=True,\n                                              class_mode=\"raw\",\n                                              target_size=(224,224))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up Validation Generator","metadata":{}},{"cell_type":"code","source":"valid_generator = datagen.flow_from_dataframe(dataframe= traindf,\n                                              directory='/kaggle/input/rvlcdip/data_final/',\n                                              x_col = 'path',\n                                              y_col = 'label',\n                                              subset = 'validation',\n                                              batch_size=100,\n                                              seed=42,\n                                              shuffle=True,\n                                              class_mode=\"raw\",\n                                              target_size=(224,224))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating directories to save models","metadata":{}},{"cell_type":"code","source":"!mkdir model_save1 logs1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model-1 Custom CNN from Scratch","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dense(16, activation='softmax')  # Assuming 16 classes\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Printing model summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialisng all the callbacks","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nimport os\nimport datetime\n\ncheckpoint_path = \"/kaggle/working/model_checkpoints/weights.{epoch:02d}-{val_loss:.2f}.keras\"\nlog_dir = \"/kaggle/working/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncallbacks = [\n    ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001),\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    TensorBoard(log_dir=log_dir, histogram_freq=1)\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nimport os\nimport datetime\n\ncheckpoint_path = \"/kaggle/working/model_checkpoints/weights.{epoch:02d}-{val_loss:.2f}.keras\"\nlog_dir = \"/kaggle/working/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncallbacks = [\n    ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001),\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    TensorBoard(log_dir=log_dir, histogram_freq=1)\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluaiton","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(validation_generator)\nprint(f'Validation loss: {loss}')\nprint(f'Validation accuracy: {accuracy}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance Plots","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}